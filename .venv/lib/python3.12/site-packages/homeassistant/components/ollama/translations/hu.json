{
    "config": {
        "abort": {
            "download_failed": "A modell let\u00f6lt\u00e9se nem siker\u00fclt"
        },
        "error": {
            "cannot_connect": "Sikertelen csatlakoz\u00e1s",
            "unknown": "V\u00e1ratlan hiba"
        },
        "progress": {
            "download": "K\u00e9rj\u00fck, v\u00e1rjon, am\u00edg a modell let\u00f6lt\u0151dik, ami nagyon hossz\u00fa id\u0151t vehet ig\u00e9nybe. Tov\u00e1bbi r\u00e9szletek\u00e9rt tekintse meg az Ollama szerver napl\u00f3it."
        },
        "step": {
            "download": {
                "title": "Modell let\u00f6lt\u00e9se"
            },
            "user": {
                "data": {
                    "model": "Modell",
                    "url": "URL"
                }
            }
        }
    },
    "options": {
        "step": {
            "init": {
                "data": {
                    "keep_alive": "\u00c9letben tart\u00e1s",
                    "llm_hass_api": "Home Assistant vez\u00e9rl\u00e9se",
                    "max_history": "El\u0151zm\u00e9ny\u00fczenetek maxim\u00e1lis sz\u00e1ma",
                    "num_ctx": "Kontextus ablak m\u00e9rete",
                    "prompt": "Utas\u00edt\u00e1sok"
                },
                "data_description": {
                    "keep_alive": "Az id\u0151tartam m\u00e1sodpercben, ameddig az Ollama a modellt a mem\u00f3ri\u00e1ban tartja. -1 = hat\u00e1rozatlan ideig, 0 = soha.",
                    "num_ctx": "Az a maxim\u00e1lis sz\u00f6veges tokenmennyis\u00e9g, amelyet a modell k\u00e9pes feldolgozni. Cs\u00f6kkentse az Ollama RAM ig\u00e9ny\u00e9nek m\u00e9rs\u00e9kl\u00e9s\u00e9hez, vagy n\u00f6velje nagyobb sz\u00e1m\u00fa megjelen\u00edtett entit\u00e1s eset\u00e9n.",
                    "prompt": "Adja meg, hogyan kell a nagy nyelvi modellnek (LLM) v\u00e1laszolnia. Ez lehet egy sablon."
                }
            }
        }
    }
}